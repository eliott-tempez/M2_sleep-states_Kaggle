{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_data = pd.read_csv('../data/featured_train_series.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "train_data['event_binary'] = train_data['event'].apply(lambda x: 1 if x != 0 else 0)\n",
    "\n",
    "X = train_data.drop(['event', 'event_binary', 'series_id'], axis=1)\n",
    "y_event = train_data['event_binary']\n",
    "y_type = train_data['event']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode the labels\n",
    "encoder = LabelEncoder()\n",
    "y_event = encoder.fit_transform(y_event)\n",
    "y_type = encoder.fit_transform(y_type)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_event_train, y_event_val, y_type_train, y_type_val = train_test_split(\n",
    "    X, y_event, y_type, test_size=0.2, stratify=y_event, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Clip predictions to avoid log(0) errors\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # Calculate weighted binary cross-entropy\n",
    "        loss = - (weights[0] * y_true * K.log(y_pred) + weights[1] * (1 - y_true) * K.log(1 - y_pred))\n",
    "        return K.mean(loss)\n",
    "    return loss\n",
    "\n",
    "# Stage 1: Event Detection\n",
    "def build_event_detection_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Stage 2: Onset vs. Wakeup Classification\n",
    "def build_event_type_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_dim=input_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 0.4405 - val_accuracy: 0.8003 - val_loss: 0.3740\n",
      "Epoch 2/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.3556 - val_accuracy: 0.8065 - val_loss: 0.3538\n",
      "Epoch 3/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3471 - val_accuracy: 0.8065 - val_loss: 0.3681\n",
      "Epoch 4/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3414 - val_accuracy: 0.8184 - val_loss: 0.3355\n",
      "Epoch 5/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3373 - val_accuracy: 0.8128 - val_loss: 0.3546\n",
      "Epoch 6/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3350 - val_accuracy: 0.8046 - val_loss: 0.3681\n",
      "Epoch 7/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.3325 - val_accuracy: 0.8051 - val_loss: 0.3660\n",
      "Epoch 8/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.3313 - val_accuracy: 0.8105 - val_loss: 0.3583\n",
      "Epoch 9/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3286 - val_accuracy: 0.8190 - val_loss: 0.3500\n",
      "Epoch 10/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8661 - loss: 0.3275 - val_accuracy: 0.8049 - val_loss: 0.3763\n",
      "Epoch 11/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3264 - val_accuracy: 0.8208 - val_loss: 0.3396\n",
      "Epoch 12/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3249 - val_accuracy: 0.8249 - val_loss: 0.3336\n",
      "Epoch 13/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.8674 - loss: 0.3249 - val_accuracy: 0.8140 - val_loss: 0.3478\n",
      "Epoch 14/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.8683 - loss: 0.3243 - val_accuracy: 0.8184 - val_loss: 0.3332\n",
      "Epoch 15/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3230 - val_accuracy: 0.8136 - val_loss: 0.3331\n",
      "Epoch 16/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3225 - val_accuracy: 0.8193 - val_loss: 0.3359\n",
      "Epoch 17/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3220 - val_accuracy: 0.8091 - val_loss: 0.3540\n",
      "Epoch 18/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.8694 - loss: 0.3207 - val_accuracy: 0.8137 - val_loss: 0.3446\n",
      "Epoch 19/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3191 - val_accuracy: 0.8222 - val_loss: 0.3265\n",
      "Epoch 20/20\n",
      "\u001b[1m17014/17014\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2ms/step - accuracy: 0.8698 - loss: 0.3196 - val_accuracy: 0.8114 - val_loss: 0.3525\n",
      "\u001b[1m17176/17176\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 738us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 2. Apply SMOTE for Stage 1\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_event_train_smote = smote.fit_resample(X_train, y_event_train)\n",
    "\n",
    "# Calculate the class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_event_train_smote),\n",
    "    y=y_event_train_smote\n",
    ")\n",
    "\n",
    "# Convert class weights to a dictionary format required by Keras\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# 3. Train Stage 1 Model\n",
    "event_detection_model = build_event_detection_model(X_train.shape[1])\n",
    "event_detection_model.fit(X_train_smote, y_event_train_smote, \n",
    "                          epochs=20, batch_size=64, \n",
    "                          validation_data=(X_val, y_event_val),\n",
    "                          class_weight=class_weights_dict)\n",
    "\n",
    "# 4. Predict events and filter for Stage 2\n",
    "event_predictions = (event_detection_model.predict(X_train) > 0.5).astype(int)\n",
    "event_indices = event_predictions.flatten() == 1\n",
    "\n",
    "# Filter the event data for Stage 2\n",
    "X_events = X_train[event_indices]\n",
    "y_type_events = y_type_train[event_indices]\n",
    "\n",
    "# Apply SMOTE for Stage 2\n",
    "X_events_smote, y_type_events_smote = smote.fit_resample(X_events, y_type_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.7683 - loss: 0.4577 - val_accuracy: 0.9981 - val_loss: 0.0064\n",
      "Epoch 2/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.3754 - val_accuracy: 0.9994 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8191 - loss: 0.3631 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
      "Epoch 4/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8250 - loss: 0.3540 - val_accuracy: 0.9996 - val_loss: 0.0019\n",
      "Epoch 5/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8294 - loss: 0.3484 - val_accuracy: 0.9996 - val_loss: 0.0013\n",
      "Epoch 6/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.3436 - val_accuracy: 0.9998 - val_loss: 9.3901e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3392 - val_accuracy: 0.9998 - val_loss: 7.8353e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.3364 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
      "Epoch 9/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3344 - val_accuracy: 0.9998 - val_loss: 8.5507e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.3328 - val_accuracy: 0.9998 - val_loss: 6.1086e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.3297 - val_accuracy: 0.9998 - val_loss: 8.6895e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3271 - val_accuracy: 0.9997 - val_loss: 9.3115e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8485 - loss: 0.3251 - val_accuracy: 0.9994 - val_loss: 0.0013\n",
      "Epoch 14/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3242 - val_accuracy: 0.9997 - val_loss: 0.0011\n",
      "Epoch 15/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3217 - val_accuracy: 0.9998 - val_loss: 8.4076e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8495 - loss: 0.3224 - val_accuracy: 0.9997 - val_loss: 8.9396e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8502 - loss: 0.3215 - val_accuracy: 0.9997 - val_loss: 9.5546e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3204 - val_accuracy: 0.9996 - val_loss: 6.3274e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3182 - val_accuracy: 0.9996 - val_loss: 7.9350e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m3815/3815\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8540 - loss: 0.3170 - val_accuracy: 0.9996 - val_loss: 6.2563e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f83c1813fb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# One-hot encode y_type_events for multi-class classification\n",
    "y_type_events_smote = keras.utils.to_categorical(y_type_events_smote - 1)  # Classes: 0 (onset), 1 (wakeup)\n",
    "\n",
    "# 5. Train Stage 2 Model\n",
    "event_type_model = build_event_type_model(X_events.shape[1])\n",
    "event_type_model.fit(X_events_smote, y_type_events_smote, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4294/4294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 708us/step\n",
      "\u001b[1m4294/4294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 654us/step\n",
      "Stage 1 - Event Detection Metrics:\n",
      "Accuracy: 0.8872\n",
      "Precision: 0.0563\n",
      "Recall: 0.6968\n",
      "F1-Score: 0.1041\n",
      "ROC-AUC: 0.7929\n",
      "Confusion Matrix:\n",
      "[[121001  15110]\n",
      " [   392    901]]\n",
      "\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Stage 2 - Onset vs. Wakeup Metrics:\n",
      "Accuracy: 0.9612\n",
      "Weighted Precision: 0.9634\n",
      "Weighted Recall: 0.9612\n",
      "Weighted F1-Score: 0.9609\n",
      "Confusion Matrix:\n",
      "[[363  34]\n",
      " [  1 503]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Onset       1.00      0.91      0.95       397\n",
      "      Wakeup       0.94      1.00      0.97       504\n",
      "\n",
      "    accuracy                           0.96       901\n",
      "   macro avg       0.97      0.96      0.96       901\n",
      "weighted avg       0.96      0.96      0.96       901\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, roc_auc_score, \n",
    "                             classification_report, precision_recall_curve)\n",
    "\n",
    "y_scores = event_detection_model.predict(X_val).ravel()\n",
    "precision, recall, thresholds = precision_recall_curve(y_event_val, y_scores)\n",
    "optimal_threshold = thresholds[np.argmax(precision * recall)] \n",
    "\n",
    "\n",
    "# Stage 1: Event Detection Evaluation\n",
    "# Predict events on validation data\n",
    "y_event_pred_val = (event_detection_model.predict(X_val) > optimal_threshold).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics for Stage 1\n",
    "stage1_accuracy = accuracy_score(y_event_val, y_event_pred_val)\n",
    "stage1_precision = precision_score(y_event_val, y_event_pred_val)\n",
    "stage1_recall = recall_score(y_event_val, y_event_pred_val)\n",
    "stage1_f1 = f1_score(y_event_val, y_event_pred_val)\n",
    "stage1_conf_matrix = confusion_matrix(y_event_val, y_event_pred_val)\n",
    "stage1_roc_auc = roc_auc_score(y_event_val, y_event_pred_val)\n",
    "\n",
    "print(\"Stage 1 - Event Detection Metrics:\")\n",
    "print(f\"Accuracy: {stage1_accuracy:.4f}\")\n",
    "print(f\"Precision: {stage1_precision:.4f}\")\n",
    "print(f\"Recall: {stage1_recall:.4f}\")\n",
    "print(f\"F1-Score: {stage1_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {stage1_roc_auc:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{stage1_conf_matrix}\\n\")\n",
    "\n",
    "# Filter predicted events for Stage 2 evaluation\n",
    "event_indices_val = y_event_pred_val.flatten() == 1\n",
    "X_events_val = X_val[event_indices_val]\n",
    "y_type_val_filtered = y_type_val[event_indices_val]\n",
    "\n",
    "# Ensure only classes 1 and 2 are present in filtered validation data\n",
    "valid_indices = (y_type_val_filtered == 1) | (y_type_val_filtered == 2)\n",
    "X_events_val = X_events_val[valid_indices]\n",
    "y_type_val_filtered = y_type_val_filtered[valid_indices]\n",
    "\n",
    "# Predict onset vs. wakeup on filtered validation data\n",
    "y_type_pred_val = event_type_model.predict(X_events_val)\n",
    "y_type_pred_val = y_type_pred_val.argmax(axis=1) + 1  # Convert from one-hot to class labels 1 and 2\n",
    "\n",
    "# Calculate evaluation metrics for Stage 2\n",
    "stage2_accuracy = accuracy_score(y_type_val_filtered, y_type_pred_val)\n",
    "stage2_precision = precision_score(y_type_val_filtered, y_type_pred_val, average='weighted')\n",
    "stage2_recall = recall_score(y_type_val_filtered, y_type_pred_val, average='weighted')\n",
    "stage2_f1 = f1_score(y_type_val_filtered, y_type_pred_val, average='weighted')\n",
    "stage2_conf_matrix = confusion_matrix(y_type_val_filtered, y_type_pred_val)\n",
    "\n",
    "# Specify labels to avoid class mismatch in classification report\n",
    "stage2_class_report = classification_report(\n",
    "    y_type_val_filtered, y_type_pred_val, target_names=['Onset', 'Wakeup'], labels=[1, 2]\n",
    ")\n",
    "\n",
    "# Print Stage 2 evaluation results\n",
    "print(\"Stage 2 - Onset vs. Wakeup Metrics:\")\n",
    "print(f\"Accuracy: {stage2_accuracy:.4f}\")\n",
    "print(f\"Weighted Precision: {stage2_precision:.4f}\")\n",
    "print(f\"Weighted Recall: {stage2_recall:.4f}\")\n",
    "print(f\"Weighted F1-Score: {stage2_f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{stage2_conf_matrix}\\n\")\n",
    "print(f\"Classification Report:\\n{stage2_class_report}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9494/9494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 628us/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Test Data - Onset vs. Wakeup Metrics:\n",
      "Accuracy: 0.3926\n",
      "Weighted Precision: 1.0000\n",
      "Weighted Recall: 0.3926\n",
      "Weighted F1-Score: 0.5638\n",
      "Confusion Matrix:\n",
      "[[ 667 1032]\n",
      " [   0    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Onset       1.00      0.39      0.56      1699\n",
      "      Wakeup       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39      1699\n",
      "   macro avg       0.50      0.20      0.28      1699\n",
      "weighted avg       1.00      0.39      0.56      1699\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/nadia/miniconda3/envs/sleep-states/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "test_data = pd.read_csv('../data/featured_test_series.csv')\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = test_data.drop(['series_id', 'event'], axis=1)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Encode the test labels\n",
    "y_test_event = test_data['event']\n",
    "y_test_event = encoder.transform(y_test_event)\n",
    "y_test_type = test_data['event'].apply(lambda x: 1 if x != 0 else 0)\n",
    "y_test_type = encoder.transform(y_test_type)\n",
    "\n",
    "# Predict events on test data\n",
    "y_test_event_pred = (event_detection_model.predict(X_test) > optimal_threshold).astype(int)\n",
    "\n",
    "# Filter predicted events for Stage 2\n",
    "event_indices_test = y_test_event_pred.flatten() == 1\n",
    "X_events_test = X_test[event_indices_test]\n",
    "y_test_type_filtered = y_test_type[event_indices_test]\n",
    "\n",
    "# Ensure only classes 1 and 2 are present in filtered test data\n",
    "valid_indices_test = (y_test_type_filtered == 1) | (y_test_type_filtered == 2)\n",
    "X_events_test = X_events_test[valid_indices_test]\n",
    "y_test_type_filtered = y_test_type_filtered[valid_indices_test]\n",
    "\n",
    "# Predict onset vs. wakeup on filtered test data\n",
    "y_test_type_pred = event_type_model.predict(X_events_test)\n",
    "y_test_type_pred = y_test_type_pred.argmax(axis=1) + 1  # Convert from one-hot to class labels 1 and 2\n",
    "\n",
    "# Calculate evaluation metrics for Stage 2 on test data\n",
    "test_accuracy = accuracy_score(y_test_type_filtered, y_test_type_pred)\n",
    "test_precision = precision_score(y_test_type_filtered, y_test_type_pred, average='weighted')\n",
    "test_recall = recall_score(y_test_type_filtered, y_test_type_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test_type_filtered, y_test_type_pred, average='weighted')\n",
    "test_conf_matrix = confusion_matrix(y_test_type_filtered, y_test_type_pred)\n",
    "\n",
    "# Specify labels to avoid class mismatch in classification report\n",
    "test_class_report = classification_report(\n",
    "    y_test_type_filtered, y_test_type_pred, target_names=['Onset', 'Wakeup'], labels=[1, 2]\n",
    ")\n",
    "\n",
    "# Print Stage 2 evaluation results on test data\n",
    "print(\"Test Data - Onset vs. Wakeup Metrics:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Weighted Precision: {test_precision:.4f}\")\n",
    "print(f\"Weighted Recall: {test_recall:.4f}\")\n",
    "print(f\"Weighted F1-Score: {test_f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{test_conf_matrix}\\n\")\n",
    "print(f\"Classification Report:\\n{test_class_report}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep-states",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
